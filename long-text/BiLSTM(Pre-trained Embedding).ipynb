{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9a2c968-d533-471a-9fb7-95a5a77c64c2",
   "metadata": {},
   "source": [
    "## 1. 读取数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86370b66-5cb7-4bd0-87cc-d91a39927262",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "import jieba\n",
    "from tqdm import tqdm\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73058962-323f-4b7b-acc8-3db6bc258c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model parameters\n",
    "embedding_size = 100\n",
    "n_hidden = 256\n",
    "n_categories = 3\n",
    "\n",
    "## Training parameters\n",
    "max_train_epochs = 3\n",
    "batch_size = 1\n",
    "warmup_proportion = 0.1\n",
    "gradient_accumulation_steps = 4\n",
    "learning_rate = 2e-5\n",
    "weight_decay = 0.01\n",
    "max_grad_norm = 1.0\n",
    "\n",
    "## Dataset parameters\n",
    "training_set_split = 0.7\n",
    "label_to_id = {'时尚': 0, '家居': 1, '教育': 2}\n",
    "sample_ratio = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e30d7a42-5673-4f6d-a302-80c8877e4ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_label(categories, frac):\n",
    "    _files, _labels = [], []\n",
    "    for category in categories:\n",
    "        dir_path = f'THUCNews/{category}/'\n",
    "        file_list = os.listdir(dir_path)\n",
    "        file_list = random.sample(file_list, int(frac * len(file_list)))\n",
    "        file_list = [dir_path + file for file in file_list]\n",
    "        _files += file_list\n",
    "        _labels += [category] * len(file_list)\n",
    "    return _files, _labels\n",
    "\n",
    "all_files, all_labels = get_file_label(categories=list(label_to_id.keys()), frac=sample_ratio)\n",
    "dataset_length = len(all_labels)\n",
    "data_list = [(all_files[idx], all_labels[idx]) for idx in range(dataset_length)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903eb099-c057-4390-8e65-78c6db03c93a",
   "metadata": {},
   "source": [
    "## 2. 构造数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91a74d69-8202-4511-80a3-0b7ba406e7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchdata.datapipes.map import SequenceWrapper\n",
    "\n",
    "datapipe = SequenceWrapper(data_list).shuffle()\n",
    "train_datapipe, test_datapipe = datapipe.random_split(\n",
    "    total_length=dataset_length, \n",
    "    weights={\"train\": training_set_split, \"test\": 1-training_set_split}, \n",
    "    seed=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5558ba1a-2ad6-4f60-bede-a4b04525b315",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2000001it [00:45, 43530.62it/s]\n"
     ]
    }
   ],
   "source": [
    "## Load word embedding\n",
    "f = open('tencent-ailab-embedding-zh-d100-v0.2.0-s.txt', encoding='utf8')\n",
    "word2v = {}\n",
    "for l in tqdm(f):\n",
    "    l = l.strip().split(' ')\n",
    "    word2v[l[0]] = list(map(float, l[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c5d9ff8-d73b-4cfd-abea-3024760148d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_batch(batch):\n",
    "    text_list, label_list = [], []\n",
    "    \n",
    "    words_list = [list(jieba.cut(b[0])) for b in batch]\n",
    "    max_length = max(len(words) for words in words_list)\n",
    "    \n",
    "    for idx, b in enumerate(batch):\n",
    "        text_tensor = torch.zeros(max_length, 100, dtype=torch.float)\n",
    "        for idx, word in enumerate(words_list[idx]):\n",
    "            if word in word2v:\n",
    "                text_tensor[idx] = torch.tensor(word2v[word], dtype=torch.float)\n",
    "        text_list.append(text_tensor)\n",
    "        label_list.append(label_to_id[b[1]])\n",
    "    \n",
    "    text_tensor = torch.stack(text_list)\n",
    "    label_tensor = torch.LongTensor(label_list)\n",
    "\n",
    "    return text_tensor, label_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0396bd80-4da7-44ec-a880-5f9c5ad134e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/97/5s9vc3hs2nj936lfdqch4zsr0000gn/T/jieba.cache\n",
      "Loading model cost 0.433 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 1.2521e-01, -7.5365e-01,  4.8382e-01,  2.6638e-01, -1.1928e-01,\n",
       "            3.0024e-01, -4.2499e-01, -2.5633e-01,  2.0186e-01, -6.8860e-03,\n",
       "           -4.7206e-01,  1.0690e-01, -1.9358e-01,  1.6714e-01,  5.0196e-01,\n",
       "           -1.3724e-01, -5.8143e-02,  1.0223e-01, -1.5010e-01,  3.5722e-01,\n",
       "            5.0096e-01, -1.3088e-02, -3.4673e-01, -3.6330e-01,  3.7184e-01,\n",
       "            3.6912e-01, -7.9310e-02,  1.3778e-01,  2.8428e-01,  7.9083e-02,\n",
       "            1.1912e-01,  4.8580e-03,  4.2114e-01, -7.3906e-01, -5.1964e-01,\n",
       "            2.6109e-01, -2.3697e-01, -1.3615e-01, -2.2766e-01, -4.7430e-01,\n",
       "           -9.9791e-02,  3.5361e-02,  8.5400e-01, -2.4759e-01, -2.7816e-02,\n",
       "            5.2931e-01, -2.4311e-01,  3.0474e-01,  1.8179e-01, -1.8875e-01,\n",
       "           -1.2094e-01, -4.8651e-01, -1.5021e-01, -3.4602e-01, -4.0085e-01,\n",
       "            3.4857e-01,  3.5714e-01,  6.5571e-01, -9.8738e-02, -3.4422e-01,\n",
       "           -9.8668e-02, -3.4280e-01,  2.2029e-01,  5.8252e-01, -1.8872e-01,\n",
       "            7.8782e-02,  5.9280e-01, -2.9061e-01, -1.4591e-01,  3.3894e-01,\n",
       "            1.8760e-01,  1.0254e-01, -2.0297e-01,  3.4713e-01, -5.3024e-01,\n",
       "           -1.5640e-02, -7.5865e-01, -1.5901e-01, -5.5917e-02, -1.1855e-01,\n",
       "           -1.2350e-03,  1.7428e-01,  1.4420e-01, -8.8424e-01, -5.1758e-01,\n",
       "           -5.9774e-01, -4.9157e-01, -5.3078e-01,  1.4249e-01,  1.4132e-01,\n",
       "           -1.7037e-01, -8.8336e-02, -3.4109e-01,  7.4069e-01, -8.2378e-02,\n",
       "           -2.8080e-01,  3.3630e-01, -1.1989e-01,  2.0504e-01,  2.7524e-01],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 1.2521e-01, -7.5365e-01,  4.8382e-01,  2.6638e-01, -1.1928e-01,\n",
       "            3.0024e-01, -4.2499e-01, -2.5633e-01,  2.0186e-01, -6.8860e-03,\n",
       "           -4.7206e-01,  1.0690e-01, -1.9358e-01,  1.6714e-01,  5.0196e-01,\n",
       "           -1.3724e-01, -5.8143e-02,  1.0223e-01, -1.5010e-01,  3.5722e-01,\n",
       "            5.0096e-01, -1.3088e-02, -3.4673e-01, -3.6330e-01,  3.7184e-01,\n",
       "            3.6912e-01, -7.9310e-02,  1.3778e-01,  2.8428e-01,  7.9083e-02,\n",
       "            1.1912e-01,  4.8580e-03,  4.2114e-01, -7.3906e-01, -5.1964e-01,\n",
       "            2.6109e-01, -2.3697e-01, -1.3615e-01, -2.2766e-01, -4.7430e-01,\n",
       "           -9.9791e-02,  3.5361e-02,  8.5400e-01, -2.4759e-01, -2.7816e-02,\n",
       "            5.2931e-01, -2.4311e-01,  3.0474e-01,  1.8179e-01, -1.8875e-01,\n",
       "           -1.2094e-01, -4.8651e-01, -1.5021e-01, -3.4602e-01, -4.0085e-01,\n",
       "            3.4857e-01,  3.5714e-01,  6.5571e-01, -9.8738e-02, -3.4422e-01,\n",
       "           -9.8668e-02, -3.4280e-01,  2.2029e-01,  5.8252e-01, -1.8872e-01,\n",
       "            7.8782e-02,  5.9280e-01, -2.9061e-01, -1.4591e-01,  3.3894e-01,\n",
       "            1.8760e-01,  1.0254e-01, -2.0297e-01,  3.4713e-01, -5.3024e-01,\n",
       "           -1.5640e-02, -7.5865e-01, -1.5901e-01, -5.5917e-02, -1.1855e-01,\n",
       "           -1.2350e-03,  1.7428e-01,  1.4420e-01, -8.8424e-01, -5.1758e-01,\n",
       "           -5.9774e-01, -4.9157e-01, -5.3078e-01,  1.4249e-01,  1.4132e-01,\n",
       "           -1.7037e-01, -8.8336e-02, -3.4109e-01,  7.4069e-01, -8.2378e-02,\n",
       "           -2.8080e-01,  3.3630e-01, -1.1989e-01,  2.0504e-01,  2.7524e-01],\n",
       "          [-2.6027e-01, -3.8277e-01,  7.4699e-02,  4.0742e-01,  4.6868e-02,\n",
       "            6.1366e-01, -6.2061e-01, -1.0037e-01, -2.5378e-02,  2.4177e-01,\n",
       "            1.6835e-01, -3.6238e-01, -3.2496e-01,  4.2039e-01,  6.9950e-02,\n",
       "            1.2440e-01, -2.0526e-01, -3.7878e-01, -4.4319e-01, -2.8896e-01,\n",
       "           -9.5247e-02,  1.2149e-01, -1.3758e-01, -2.0690e-01,  5.8889e-01,\n",
       "            1.0249e-01,  1.6675e-01,  6.5346e-01,  1.5178e-01,  1.9346e-01,\n",
       "           -4.3713e-01, -6.8802e-01,  2.7356e-01,  4.1151e-01,  6.2550e-03,\n",
       "            8.4124e-02,  1.5105e-01, -7.0040e-03,  1.0901e-01, -5.0806e-01,\n",
       "            1.7340e-01, -4.8466e-01, -1.4390e-02, -4.9083e-01, -4.2586e-01,\n",
       "           -8.2687e-02, -7.3554e-01,  2.2385e-01,  2.8677e-01, -2.3230e-01,\n",
       "            1.0427e-01, -1.0262e+00,  3.1327e-01, -2.5931e-01, -7.6218e-02,\n",
       "            4.2308e-01,  1.7229e-01,  5.7801e-01,  2.1672e-02, -3.3964e-01,\n",
       "           -3.3738e-01,  4.1425e-01, -6.7504e-02, -2.5370e-01,  1.3761e-01,\n",
       "           -4.0566e-01,  4.2536e-01,  1.1632e-01,  8.6272e-02, -3.1608e-01,\n",
       "           -2.3251e-02,  3.7481e-01,  4.7130e-01, -3.1739e-01,  8.4423e-02,\n",
       "            4.4494e-01, -1.8250e-01, -1.4271e-01,  1.7548e-01,  5.6703e-02,\n",
       "            2.3911e-01,  3.1542e-01,  2.7372e-01, -1.3121e-01,  1.3327e-01,\n",
       "           -1.1267e-01,  1.7748e-02, -1.7027e-01, -1.1427e-01, -1.2496e-01,\n",
       "           -4.4853e-01,  4.7921e-01, -3.7066e-01, -1.5747e-01, -1.2787e-01,\n",
       "           -2.1433e-01, -3.7199e-01,  4.7745e-02,  2.1972e-01, -1.2944e-01],\n",
       "          [ 1.2521e-01, -7.5365e-01,  4.8382e-01,  2.6638e-01, -1.1928e-01,\n",
       "            3.0024e-01, -4.2499e-01, -2.5633e-01,  2.0186e-01, -6.8860e-03,\n",
       "           -4.7206e-01,  1.0690e-01, -1.9358e-01,  1.6714e-01,  5.0196e-01,\n",
       "           -1.3724e-01, -5.8143e-02,  1.0223e-01, -1.5010e-01,  3.5722e-01,\n",
       "            5.0096e-01, -1.3088e-02, -3.4673e-01, -3.6330e-01,  3.7184e-01,\n",
       "            3.6912e-01, -7.9310e-02,  1.3778e-01,  2.8428e-01,  7.9083e-02,\n",
       "            1.1912e-01,  4.8580e-03,  4.2114e-01, -7.3906e-01, -5.1964e-01,\n",
       "            2.6109e-01, -2.3697e-01, -1.3615e-01, -2.2766e-01, -4.7430e-01,\n",
       "           -9.9791e-02,  3.5361e-02,  8.5400e-01, -2.4759e-01, -2.7816e-02,\n",
       "            5.2931e-01, -2.4311e-01,  3.0474e-01,  1.8179e-01, -1.8875e-01,\n",
       "           -1.2094e-01, -4.8651e-01, -1.5021e-01, -3.4602e-01, -4.0085e-01,\n",
       "            3.4857e-01,  3.5714e-01,  6.5571e-01, -9.8738e-02, -3.4422e-01,\n",
       "           -9.8668e-02, -3.4280e-01,  2.2029e-01,  5.8252e-01, -1.8872e-01,\n",
       "            7.8782e-02,  5.9280e-01, -2.9061e-01, -1.4591e-01,  3.3894e-01,\n",
       "            1.8760e-01,  1.0254e-01, -2.0297e-01,  3.4713e-01, -5.3024e-01,\n",
       "           -1.5640e-02, -7.5865e-01, -1.5901e-01, -5.5917e-02, -1.1855e-01,\n",
       "           -1.2350e-03,  1.7428e-01,  1.4420e-01, -8.8424e-01, -5.1758e-01,\n",
       "           -5.9774e-01, -4.9157e-01, -5.3078e-01,  1.4249e-01,  1.4132e-01,\n",
       "           -1.7037e-01, -8.8336e-02, -3.4109e-01,  7.4069e-01, -8.2378e-02,\n",
       "           -2.8080e-01,  3.3630e-01, -1.1989e-01,  2.0504e-01,  2.7524e-01],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 2.1656e-01, -2.8570e-01,  2.0179e-01,  1.4092e-01, -2.5943e-01,\n",
       "            1.2181e-01, -3.8210e-01, -2.2765e-01,  3.7229e-01,  1.7845e-01,\n",
       "           -1.1407e-01,  3.4616e-01,  1.7749e-01,  6.6906e-02,  2.3099e-01,\n",
       "           -2.1085e-01, -3.1895e-02, -2.9152e-01,  1.1438e-01,  2.2826e-01,\n",
       "            2.4553e-01, -2.9165e-01, -3.3803e-01, -2.5371e-01,  5.6930e-02,\n",
       "            4.3951e-01,  8.5458e-02,  3.9019e-01, -1.2658e-01,  1.5092e-01,\n",
       "            1.3599e-01, -1.9948e-01, -4.5788e-02, -1.6845e-01, -2.2272e-01,\n",
       "            6.7160e-02, -6.4363e-02,  2.0501e-01, -2.1055e-02, -4.3261e-02,\n",
       "            1.2556e-02, -5.6350e-03,  3.3371e-01, -2.2870e-01,  2.1507e-01,\n",
       "            3.1595e-01, -5.6156e-02,  6.3808e-01,  3.4090e-01, -2.9795e-02,\n",
       "           -3.7649e-01, -2.2216e-01,  1.1557e-01, -2.9610e-01, -3.4920e-01,\n",
       "            5.5013e-02,  1.8059e-01,  5.8887e-01, -4.1371e-02, -4.1673e-01,\n",
       "            1.6848e-01, -1.4450e-03,  1.3625e-01,  1.8306e-01,  2.7004e-02,\n",
       "            2.3658e-02,  1.3758e-01,  8.7589e-02,  2.6181e-01,  1.7241e-01,\n",
       "            2.2887e-01,  2.2686e-01, -2.7002e-02,  1.6657e-01, -2.1217e-01,\n",
       "            4.0123e-01, -5.7150e-02, -1.7223e-01, -1.4083e-01,  1.3516e-01,\n",
       "            1.9367e-01,  1.0170e-01,  1.8577e-01, -7.0859e-02, -1.0061e-01,\n",
       "           -2.5489e-01, -3.6030e-01, -1.5820e-01, -3.2130e-03, -1.0546e-01,\n",
       "           -1.0552e-01, -5.7003e-02,  2.3026e-01,  1.2196e-02, -3.5844e-01,\n",
       "           -3.1383e-01, -7.9749e-02,  1.9927e-01,  3.7012e-01, -3.2881e-01],\n",
       "          [ 2.8251e-01, -1.4611e-01, -1.9643e-01, -9.7556e-02, -1.5581e-01,\n",
       "            2.1681e-01, -2.2945e-01, -8.0840e-03,  4.4159e-01,  5.2380e-01,\n",
       "           -7.0257e-01,  5.9779e-01, -2.5957e-01,  1.5427e-01, -5.2623e-02,\n",
       "           -4.7363e-01, -1.9571e-01, -3.3914e-01, -1.4431e-01,  8.1817e-01,\n",
       "           -6.7524e-01, -4.4493e-01, -8.8221e-02, -1.0366e+00,  7.1181e-01,\n",
       "            3.9639e-01,  3.4696e-01,  5.0862e-01, -5.0413e-01,  7.8383e-01,\n",
       "            7.8646e-01,  2.5028e-01,  4.7676e-01,  3.2665e-01, -2.1896e-01,\n",
       "            1.8255e-01, -2.2963e-01,  2.1759e-01,  3.0804e-01, -1.0145e+00,\n",
       "           -2.2753e-01,  1.2125e-01,  8.4589e-01,  2.7480e-01, -7.6750e-01,\n",
       "            5.4680e-03, -4.7699e-01, -2.5039e-01,  4.3120e-01,  1.8118e-01,\n",
       "           -6.9514e-01, -6.2311e-01, -3.9763e-01, -3.7554e-01, -2.3238e-02,\n",
       "            3.2317e-01,  8.6902e-01,  8.0443e-01, -4.8052e-01, -5.1201e-01,\n",
       "            3.5562e-01, -2.6698e-01,  8.6777e-01,  3.5054e-01,  3.5908e-01,\n",
       "           -2.7860e-01,  2.5719e-01,  1.9333e-02,  3.4002e-01, -4.8633e-01,\n",
       "            1.3752e-01,  1.9600e-04,  2.1808e-01, -2.5989e-01, -6.2229e-01,\n",
       "           -5.3475e-02,  2.7312e-01, -1.0703e-01, -1.1792e+00, -1.6057e-01,\n",
       "            1.3291e-01, -2.0462e-01,  2.3092e-01,  8.1685e-02,  7.8974e-01,\n",
       "           -2.0354e-01, -1.3681e-01, -2.1006e-01, -1.6994e-01,  9.8417e-02,\n",
       "            1.9434e-01, -8.8443e-02, -8.2011e-02,  2.6035e-01, -3.5204e-01,\n",
       "           -5.9802e-01,  1.2266e-01, -2.8798e-01, -5.9045e-02,  5.0256e-01]]]),\n",
       " tensor([1]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader = DataLoader(train_datapipe, batch_size=batch_size, collate_fn=collate_batch)\n",
    "test_loader = DataLoader(test_datapipe, batch_size=batch_size, collate_fn=collate_batch)\n",
    "\n",
    "next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e6df07-1b5c-40c6-99c2-cdeb4149e37a",
   "metadata": {},
   "source": [
    "## 3. 定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d53f5483-0e40-4b84-8cdf-55f5d52207f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9711f38-ad88-4d3c-8b00-2d663c72b531",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, embedding_size, hidden_size, output_size):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.LSTM = nn.LSTM(embedding_size, hidden_size, num_layers=2, bidirectional=True, batch_first=True)\n",
    "        self.cls = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "    def forward(self, input_tensor):\n",
    "        word_vector = input_tensor\n",
    "        output = self.LSTM(word_vector)\n",
    "        # print(\"output shape:\", output[0][:, -1, :].shape)\n",
    "        output = output[0][:, -1, :].reshape(batch_size, 2, -1).sum(axis=1)\n",
    "        output = self.cls(output)\n",
    "        output = self.softmax(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "raw",
   "id": "28d138de-3c11-4b5c-916b-8d8914f26433",
   "metadata": {},
   "source": [
    "def train(rnn, criterion, input_tensor, category_tensor, lr):\n",
    "    rnn.zero_grad()\n",
    "    output = rnn(input_tensor)\n",
    "    # print(\"output:\", output)\n",
    "    # print(\"category_tensor:\", category_tensor)\n",
    "    loss = criterion(output, category_tensor)\n",
    "    loss.backward()\n",
    "\n",
    "    return output, loss.item()\n",
    "\n",
    "\n",
    "def evaluate(rnn, input_tensor):\n",
    "    with torch.no_grad():\n",
    "        output = rnn(input_tensor)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d82ebde-eba0-42c5-aec5-e26f13282b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c55beed-3a40-4e2f-bc4f-f2e96d1c1f8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training(total) Steps: 13840\n",
      "Warm-up Steps: 1384\n"
     ]
    }
   ],
   "source": [
    "## Set model\n",
    "lstm = LSTM(embedding_size, n_hidden, n_categories)\n",
    "lstm.to(device)\n",
    "\n",
    "## Optimizer settings\n",
    "param_optimizer = list(lstm.named_parameters())\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for _, p in param_optimizer], 'weight_decay': weight_decay},\n",
    "]\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate)\n",
    "\n",
    "## Scheduler settings\n",
    "total_steps = int(dataset_length * training_set_split) // gradient_accumulation_steps * max_train_epochs + 1\n",
    "warmup_steps = int(warmup_proportion * total_steps)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=warmup_steps, num_training_steps=total_steps)\n",
    "print(f'Training(total) Steps: {total_steps}\\nWarm-up Steps: {warmup_steps}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0bbde987-9930-4aae-91be-c9e3b14c7b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18455/18455 [04:10<00:00, 73.72it/s]\n",
      "100%|██████████| 7910/7910 [00:16<00:00, 477.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 7910, Correct: 7910, Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18455/18455 [04:06<00:00, 74.82it/s]\n",
      "100%|██████████| 7910/7910 [00:16<00:00, 468.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 7910, Correct: 7910, Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18455/18455 [04:08<00:00, 74.16it/s]\n",
      "100%|██████████| 7910/7910 [00:16<00:00, 484.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 7910, Correct: 7910, Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from math import ceil\n",
    "\n",
    "all_losses = []\n",
    "criterion = nn.NLLLoss()\n",
    "plot_every = 100\n",
    "\n",
    "for e in range(max_train_epochs):\n",
    "    loss_sum = 0\n",
    "    with tqdm(total=int(dataset_length * training_set_split)) as pbar:\n",
    "        for ind, (text, label) in enumerate(train_loader):\n",
    "            output = lstm(text.to(device))\n",
    "            loss = criterion(output, label.to(device))\n",
    "            loss_sum += loss.item()\n",
    "            loss.backward()\n",
    "            \n",
    "            if ind * batch_size % plot_every == 0:\n",
    "                all_losses.append(loss_sum / plot_every)\n",
    "                loss_sum = 0\n",
    "            \n",
    "            if (ind + 1) % gradient_accumulation_steps == 0:\n",
    "                optimizer.step()\n",
    "                scheduler.step() \n",
    "                optimizer.zero_grad()\n",
    "            \n",
    "            pbar.update(batch_size)\n",
    "    \n",
    "    c = 0\n",
    "    test_size = ceil(dataset_length * (1 - training_set_split))\n",
    "    with tqdm(total=test_size) as pbar2:\n",
    "        for text, label in test_loader:\n",
    "            with torch.no_grad():\n",
    "                output = lstm(text.to(device))\n",
    "            topn, topi = output.topk(1)\n",
    "            # print(topi.squeeze(dim=1))\n",
    "            c += (topi.squeeze(dim=1) == label.to(device)).sum().item()\n",
    "            pbar2.update(batch_size)\n",
    "    print(f\"Total: {test_size}, Correct: {c}, Accuracy: {c/test_size:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a011182-f407-4ef8-9c10-121783a45e78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x476faf1c0>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.ylabel('Average Loss')\n",
    "plt.plot(all_losses[1:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
